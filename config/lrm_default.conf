# Default LRM configuration file.
# See lrm.agent.config.LRMConfig source code for the meaning of each parameter

[LRM]

# Reward Machines-related configuration
test_freq = 1.0
rm_init_steps = 200000
rm_u_max = 10
rm_preprocess = True
rm_tabu_size = 10000
rm_lr_steps = 100
rm_workers = 10
use_perfect_rm = False

# Generic RL configuration
gamma = 0.9
train_steps = 500000
episode_horizon = 5000
epsilon = 0.1
max_learning_steps = 500000

# Deep Q-Network configuration
lr = 5e-5
learning_starts = 50000
train_freq = 1
target_network_update_freq = 100
buffer_size = 100000
batch_size = 32
use_double_dqn = True
num_hidden_layers = 5
num_neurons = 64
use_qrm = True

# Prioritized Experience Replay configuration
prioritized_replay = False
prioritized_replay_alpha = 0.6
prioritized_replay_beta0 = 0.4
prioritized_replay_beta_iters = 0
prioritized_replay_eps = 1e-6
